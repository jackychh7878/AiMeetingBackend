version: '3.8'

services:
  ai_meeting_backend:
    image: jccatomind/ai_meeting_backend:latest
    container_name: ai_meeting_backend
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - PORT=8000
      - FLASK_APP=app.py
      - FLASK_ENV=production
      - GUNICORN_CMD_ARGS=--timeout=300 --workers=2 --threads=4 --worker-class=gthread
      - AZURE_STT_API_KEY=${AZURE_STT_API_KEY}
      - FANOLAB_HOST=${FANOLAB_HOST}
      - FANOLAB_API_KEY=${FANOLAB_API_KEY}
      - AZURE_POSTGRES_CONNECTION=${AZURE_POSTGRES_CONNECTION}
      - AZURE_CONTAINER_NAME=${AZURE_CONTAINER_NAME}
      - AZURE_ACCOUNT_NAME=${AZURE_ACCOUNT_NAME}
      - AZURE_ACCOUNT_KEY=${AZURE_ACCOUNT_KEY}
      - ON_PREMISES_MODE=${ON_PREMISES_MODE}
      - NGROK_PUBLIC_MODE=${NGROK_PUBLIC_MODE}
      - NGROK_HOST=${NGROK_HOST}
      - NGROK_ACCESS_KEY=${NGROK_ACCESS_KEY}
      - NGROK_SECRET_KEY=${NGROK_SECRET_KEY}
      - TFLOW_HOST=${TFLOW_HOST}
      - ON_PREMISES_POSTGRES_CONNECTION=${ON_PREMISES_POSTGRES_CONNECTION}
    depends_on:
      - pgvector
      - minio
      - n8n
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 5s
    volumes:
      - ./path/to/.env:/app/.env:ro
    networks:
      - ai_network

  pgvector:
    image: pgvector/pgvector:pg17
    container_name: pgvector
    environment:
      - POSTGRES_USER=sqladmin
      - POSTGRES_PASSWORD=P@ssw0rd
      - POSTGRES_DB=postgres
    ports:
      - "5432:5432"
    volumes:
      - pgvector_data:/var/lib/postgresql/data
      - ./init-schema.sql:/docker-entrypoint-initdb.d/init-schema.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U sqladmin"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 5s
    networks:
      - ai_network

  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
      - minio_config:/root/.minio
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 5s
    networks:
      - ai_network

  # Dedicated Postgres for n8n
  postgres:
    image: postgres:16-alpine
    container_name: postgres
    environment:
      - POSTGRES_USER
      - POSTGRES_PASSWORD
      - POSTGRES_DB
    ports:
      - "5433:5432"
    volumes:
      - postgres_n8n_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h localhost -U $${POSTGRES_USER} -d $${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 10
    networks:
      - ai_network

  # n8n and AI stack
  n8n-import:
    image: n8nio/n8n:latest
    container_name: n8n-import
    hostname: n8n-import
    entrypoint: /bin/sh
    command:
      - "-c"
      - "n8n import:credentials --separate --input=/demo-data/credentials && n8n import:workflow --separate --input=/demo-data/workflows"
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_USER=${POSTGRES_USER}
      - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD}
      - DB_POSTGRESDB_DATABASE=${POSTGRES_DB}
      - N8N_DIAGNOSTICS_ENABLED=false
      - N8N_PERSONALIZATION_ENABLED=false
      - OLLAMA_HOST=ollama:11434
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
      - N8N_USER_MANAGEMENT_JWT_SECRET=${N8N_USER_MANAGEMENT_JWT_SECRET}
      - N8N_DEFAULT_BINARY_DATA_MODE=${N8N_DEFAULT_BINARY_DATA_MODE}
    volumes:
      - ./n8n/demo-data:/demo-data
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - ai_network

  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    restart: unless-stopped
    ports:
      - 5678:5678
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_USER=${POSTGRES_USER}
      - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD}
      - DB_POSTGRESDB_DATABASE=${POSTGRES_DB}
      - N8N_DIAGNOSTICS_ENABLED=false
      - N8N_PERSONALIZATION_ENABLED=false
      - OLLAMA_HOST=ollama:11434
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
      - N8N_USER_MANAGEMENT_JWT_SECRET=${N8N_USER_MANAGEMENT_JWT_SECRET}
      - N8N_DEFAULT_BINARY_DATA_MODE=${N8N_DEFAULT_BINARY_DATA_MODE}
    volumes:
      - n8n_storage:/home/node/.n8n
      - ./n8n/demo-data:/demo-data
      - ./n8n/shared:/data/shared
    depends_on:
      postgres:
        condition: service_healthy
      n8n-import:
        condition: service_completed_successfully
    networks:
      - ai_network

  qdrant:
    image: qdrant/qdrant
    container_name: qdrant
    restart: unless-stopped
    ports:
      - 6333:6333
    volumes:
      - qdrant_storage:/qdrant/storage
    networks:
      - ai_network

  # Ollama CPU profile
  ollama-cpu:
    profiles: ["cpu"]
    image: ollama/ollama:latest
    container_name: ollama-cpu
    restart: unless-stopped
    ports:
      - 11434:11434
    volumes:
      - ollama_storage:/root/.ollama
    networks:
      - ai_network

  # Ollama Nvidia GPU profile
  ollama-gpu:
    profiles: ["gpu-nvidia"]
    image: ollama/ollama:latest
    container_name: ollama-gpu
    restart: unless-stopped
    ports:
      - 11434:11434
    volumes:
      - ollama_storage:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - ai_network

  # Ollama AMD GPU profile
  ollama-gpu-amd:
    profiles: ["gpu-amd"]
    image: ollama/ollama:rocm
    container_name: ollama-gpu-amd
    restart: unless-stopped
    ports:
      - 11434:11434
    volumes:
      - ollama_storage:/root/.ollama
    devices:
      - "/dev/kfd"
      - "/dev/dri"
    networks:
      - ai_network

  # Ollama pull llama for each profile
  ollama-pull-llama-cpu:
    profiles: ["cpu"]
    image: ollama/ollama:latest
    container_name: ollama-pull-llama-cpu
    entrypoint: /bin/sh
    command:
      - "-c"
      - "sleep 3; ollama pull llama3.2"
    environment:
      - OLLAMA_HOST=ollama-cpu:11434
    volumes:
      - ollama_storage:/root/.ollama
    depends_on:
      - ollama-cpu
    networks:
      - ai_network

  ollama-pull-llama-gpu:
    profiles: ["gpu-nvidia"]
    image: ollama/ollama:latest
    container_name: ollama-pull-llama-gpu
    entrypoint: /bin/sh
    command:
      - "-c"
      - "sleep 3; ollama pull llama3.2"
    environment:
      - OLLAMA_HOST=ollama-gpu:11434
    volumes:
      - ollama_storage:/root/.ollama
    depends_on:
      - ollama-gpu
    networks:
      - ai_network

  ollama-pull-llama-gpu-amd:
    profiles: ["gpu-amd"]
    image: ollama/ollama:rocm
    container_name: ollama-pull-llama-gpu-amd
    entrypoint: /bin/sh
    command:
      - "-c"
      - "sleep 3; ollama pull llama3.2"
    environment:
      - OLLAMA_HOST=ollama-gpu-amd:11434
    volumes:
      - ollama_storage:/root/.ollama
    depends_on:
      - ollama-gpu-amd
    networks:
      - ai_network

volumes:
  pgvector_data:
  minio_data:
  minio_config:
  n8n_storage:
  ollama_storage:
  qdrant_storage:
  postgres_n8n_data:

networks:
  ai_network:
    driver: bridge

 